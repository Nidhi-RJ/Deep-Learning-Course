{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import the Libraries"
      ],
      "metadata": {
        "id": "XnXXz5UL5aFN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qapKxYG9i5Hi"
      },
      "outputs": [],
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Load the MNIST dataset"
      ],
      "metadata": {
        "id": "mb3VhbAy5gEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "MQ5paq58jCgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3baf8d-d042-48fd-d875-7eef52a3c1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Reshape the dataset as per the dimensional needs for model training"
      ],
      "metadata": {
        "id": "o_9pL1dn5q7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building the input vector from the 28x28 pixels\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]).astype('float32')\n",
        "\n",
        "x_test.shape"
      ],
      "metadata": {
        "id": "kjD2uAnVlGnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72dede2b-a9ae-4631-e333-247c6e79b602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Normalize the data in dataset to the range of 0 to 1"
      ],
      "metadata": {
        "id": "lFmLiSSD56X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the data to help with the training\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "oCprw9T-jF4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. One-Hot Encoding (Because the output is categorical)"
      ],
      "metadata": {
        "id": "VIo5x4jN6G66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkKLhLFWjQEI",
        "outputId": "da83cd91-b258-4d2c-8294-332557df8e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Initializing the parameters for the model before trainig"
      ],
      "metadata": {
        "id": "6m6U_EeK6V9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the parameters\n",
        "output_dim = 10\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "batch_size = 128\n",
        "nb_epoch = 10"
      ],
      "metadata": {
        "id": "q3i89W_DPpkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Defining/Building the model"
      ],
      "metadata": {
        "id": "Uip33X7x6a2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model = Sequential()\n",
        "# flatten the sequential model\n",
        "model.add(Flatten(input_shape=(input_dim,)))\n",
        "# output Layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "mJ-rONAFjKrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Compiling and Training the Softmax model with training dataset and Calculating the accuracy with validation and test dataset"
      ],
      "metadata": {
        "id": "dJo8jYCj7RyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=nb_epoch, batch_size = batch_size, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlgZ7zBDQUx6",
        "outputId": "e5cf049b-80dd-414c-9c80-68310de896b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7850 (30.66 KB)\n",
            "Trainable params: 7850 (30.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6829 - accuracy: 0.8303 - val_loss: 0.3802 - val_accuracy: 0.9021\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.9027 - val_loss: 0.3191 - val_accuracy: 0.9139\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.9121 - val_loss: 0.2959 - val_accuracy: 0.9178\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2993 - accuracy: 0.9171 - val_loss: 0.2858 - val_accuracy: 0.9206\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2876 - accuracy: 0.9199 - val_loss: 0.2799 - val_accuracy: 0.9227\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.9227 - val_loss: 0.2726 - val_accuracy: 0.9238\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.9240 - val_loss: 0.2728 - val_accuracy: 0.9246\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.9248 - val_loss: 0.2682 - val_accuracy: 0.9250\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.9262 - val_loss: 0.2674 - val_accuracy: 0.9257\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9273 - val_loss: 0.2652 - val_accuracy: 0.9263\n",
            "313/313 - 0s - loss: 0.2652 - accuracy: 0.9263 - 407ms/epoch - 1ms/step\n",
            "Test accuracy: 0.9262999892234802 and Loss: 0.26517337560653687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeating 7th and 8th step of Softmax Regression model with dropout"
      ],
      "metadata": {
        "id": "0EVE1PyT7kWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model_with_dropout = Sequential()\n",
        "model_with_dropout.add(Flatten(input_shape=(input_dim,)))\n",
        "model_with_dropout.add(Dropout(0.2))\n",
        "model_with_dropout.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "KzICepzfTH-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model_with_dropout.summary()\n",
        "# compiling the sequential model\n",
        "model_with_dropout.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model_with_dropout.fit(x_train, y_train, epochs=nb_epoch, batch_size = batch_size, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model_with_dropout.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrkU3wObTN-B",
        "outputId": "1f8f852c-c944-4481-9ded-6bdc90feaca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7850 (30.66 KB)\n",
            "Trainable params: 7850 (30.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.7180 - accuracy: 0.8134 - val_loss: 0.3930 - val_accuracy: 0.8998\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4014 - accuracy: 0.8888 - val_loss: 0.3269 - val_accuracy: 0.9111\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8992 - val_loss: 0.3056 - val_accuracy: 0.9165\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3379 - accuracy: 0.9050 - val_loss: 0.2916 - val_accuracy: 0.9194\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3256 - accuracy: 0.9071 - val_loss: 0.2830 - val_accuracy: 0.9221\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3213 - accuracy: 0.9081 - val_loss: 0.2799 - val_accuracy: 0.9221\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3170 - accuracy: 0.9098 - val_loss: 0.2753 - val_accuracy: 0.9239\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3124 - accuracy: 0.9117 - val_loss: 0.2715 - val_accuracy: 0.9251\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.9125 - val_loss: 0.2722 - val_accuracy: 0.9238\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3057 - accuracy: 0.9140 - val_loss: 0.2704 - val_accuracy: 0.9241\n",
            "313/313 - 0s - loss: 0.2704 - accuracy: 0.9241 - 401ms/epoch - 1ms/step\n",
            "Test accuracy: 0.9240999817848206 and Loss: 0.27036768198013306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeating 7th and 8th step of Softmax Regression model with Batch Normalization"
      ],
      "metadata": {
        "id": "3aDAO9fR7tuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model_with_BN = Sequential()\n",
        "model_with_BN.add(Flatten(input_shape=(input_dim,)))\n",
        "model_with_BN.add(BatchNormalization())\n",
        "model_with_BN.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "fn1IgL9ujbc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model_with_BN.summary()\n",
        "# compiling the sequential model\n",
        "model_with_BN.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model_with_BN.fit(x_train, y_train, epochs=nb_epoch, batch_size = batch_size, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model_with_BN.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEtZonAkrUZG",
        "outputId": "b72d8bd8-c28b-4bfb-c9dd-36cc33e46e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 784)               3136      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10986 (42.91 KB)\n",
            "Trainable params: 9418 (36.79 KB)\n",
            "Non-trainable params: 1568 (6.12 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.4874 - accuracy: 0.8551 - val_loss: 0.3016 - val_accuracy: 0.9133\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3017 - accuracy: 0.9137 - val_loss: 0.2816 - val_accuracy: 0.9223\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.9194 - val_loss: 0.2825 - val_accuracy: 0.9225\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2759 - accuracy: 0.9216 - val_loss: 0.2797 - val_accuracy: 0.9234\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2700 - accuracy: 0.9245 - val_loss: 0.2840 - val_accuracy: 0.9222\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2655 - accuracy: 0.9251 - val_loss: 0.2826 - val_accuracy: 0.9227\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2628 - accuracy: 0.9261 - val_loss: 0.2867 - val_accuracy: 0.9239\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2612 - accuracy: 0.9257 - val_loss: 0.2816 - val_accuracy: 0.9251\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2601 - accuracy: 0.9270 - val_loss: 0.2871 - val_accuracy: 0.9245\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2566 - accuracy: 0.9281 - val_loss: 0.2896 - val_accuracy: 0.9242\n",
            "313/313 - 0s - loss: 0.2896 - accuracy: 0.9242 - 408ms/epoch - 1ms/step\n",
            "Test accuracy: 0.9241999983787537 and Loss: 0.2895711064338684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeating 7th and 8th step of Softmax Regression model with Batch Normalization and dropout"
      ],
      "metadata": {
        "id": "mL2vfPdr8ykL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model_with_both = Sequential()\n",
        "model_with_both.add(Flatten(input_shape=(input_dim,)))\n",
        "model_with_both.add(BatchNormalization())\n",
        "model_with_both.add(Dense(10, activation='softmax'))\n",
        "model_with_both.add(Dropout(0.2))\n"
      ],
      "metadata": {
        "id": "7YYXiwZ8rk-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model_with_both.summary()\n",
        "# compiling the sequential model\n",
        "model_with_both.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model_with_both.fit(x_train, y_train, epochs=nb_epoch, batch_size = batch_size, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model_with_both.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBn-HypX3UVZ",
        "outputId": "302ea66c-6bba-45eb-a4a6-3be9021a1242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 784)               3136      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10986 (42.91 KB)\n",
            "Trainable params: 9418 (36.79 KB)\n",
            "Non-trainable params: 1568 (6.12 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 3.5970 - accuracy: 0.6920 - val_loss: 0.3101 - val_accuracy: 0.9130\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4203 - accuracy: 0.7385 - val_loss: 0.2869 - val_accuracy: 0.9183\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.3935 - accuracy: 0.7444 - val_loss: 0.2834 - val_accuracy: 0.9191\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4339 - accuracy: 0.7428 - val_loss: 0.2812 - val_accuracy: 0.9228\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.3977 - accuracy: 0.7465 - val_loss: 0.2827 - val_accuracy: 0.9255\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4108 - accuracy: 0.7470 - val_loss: 0.2825 - val_accuracy: 0.9212\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.4196 - accuracy: 0.7467 - val_loss: 0.2852 - val_accuracy: 0.9214\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.4118 - accuracy: 0.7473 - val_loss: 0.2811 - val_accuracy: 0.9233\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4515 - accuracy: 0.7448 - val_loss: 0.2836 - val_accuracy: 0.9231\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4427 - accuracy: 0.7460 - val_loss: 0.2881 - val_accuracy: 0.9220\n",
            "313/313 - 0s - loss: 0.2881 - accuracy: 0.9220 - 418ms/epoch - 1ms/step\n",
            "Test accuracy: 0.921999990940094 and Loss: 0.28811147809028625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IS98bZTA3EQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}