{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import the Libraries"
      ],
      "metadata": {
        "id": "94NLLQ_pNqEW"
      },
      "id": "94NLLQ_pNqEW"
    },
    {
      "cell_type": "code",
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
        "from keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "MmTbAUoF8qYj"
      },
      "id": "MmTbAUoF8qYj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the MNIST dataset"
      ],
      "metadata": {
        "id": "PsnZ1WFWNszP"
      },
      "id": "PsnZ1WFWNszP"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "YI2BKUC58zRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbfb792-75bd-4f78-8206-396be68206f4"
      },
      "id": "YI2BKUC58zRv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Reshape the dataset as per the dimensional needs for model training"
      ],
      "metadata": {
        "id": "qeS3JWnGNv8X"
      },
      "id": "qeS3JWnGNv8X"
    },
    {
      "cell_type": "code",
      "source": [
        "# building the input vector from the 28x28 pixels\n",
        "print(x_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "print(x_train.shape)\n"
      ],
      "metadata": {
        "id": "vk8Evy7Tkime",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53deebb-2c72-478f-da32-0459baff7409"
      },
      "id": "vk8Evy7Tkime",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Normalize the data in dataset to the range of 0 to 1"
      ],
      "metadata": {
        "id": "Rri9bUikN1Fz"
      },
      "id": "Rri9bUikN1Fz"
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the data to help with the training\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "n2GiwhGFAv7-"
      },
      "id": "n2GiwhGFAv7-",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. One-Hot Encoding (Because the output is categorical)"
      ],
      "metadata": {
        "id": "IGuHEVsRN3b2"
      },
      "id": "IGuHEVsRN3b2"
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP2k4eko9YnE",
        "outputId": "51c3fcc6-b7cc-4557-c349-b341bdaf6044"
      },
      "id": "wP2k4eko9YnE",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Initializing the parameters for the model before training"
      ],
      "metadata": {
        "id": "YzQWuvxPN5-M"
      },
      "id": "YzQWuvxPN5-M"
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the parameters\n",
        "output_dim = 10\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "batch_size = 128\n",
        "nb_epoch = 10\n",
        "x_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf7B8dMKPo6s",
        "outputId": "e7f65c34-206d-4771-e5d4-d4b40737be67"
      },
      "id": "Rf7B8dMKPo6s",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Defining/Building the Model"
      ],
      "metadata": {
        "id": "BDecsN2wN-rD"
      },
      "id": "BDecsN2wN-rD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "62BQ4l5d-qwc"
      },
      "id": "62BQ4l5d-qwc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Compiling and Training the CNN model with training dataset and Calculating the accuracy with validation and test dataset"
      ],
      "metadata": {
        "id": "VnyCg2psOEBu"
      },
      "id": "VnyCg2psOEBu"
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWwQD6-ZQdfg",
        "outputId": "e1223f14-7159-4b40-dfd5-32c4de9cde05"
      },
      "id": "WWwQD6-ZQdfg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 25)        250       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 26, 26, 25)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16900)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               1690100   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1691360 (6.45 MB)\n",
            "Trainable params: 1691360 (6.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 45s 95ms/step - loss: 0.1940 - accuracy: 0.9440 - val_loss: 0.0784 - val_accuracy: 0.9749\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 43s 92ms/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 0.0615 - val_accuracy: 0.9804\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 43s 91ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 0.0529 - val_accuracy: 0.9822\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 44s 94ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0493 - val_accuracy: 0.9841\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 43s 93ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0521 - val_accuracy: 0.9835\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 43s 93ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.0551 - val_accuracy: 0.9841\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 44s 94ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 43s 92ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0590 - val_accuracy: 0.9842\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 43s 92ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0772 - val_accuracy: 0.9800\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 46s 98ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0728 - val_accuracy: 0.9820\n",
            "313/313 - 2s - loss: 0.0728 - accuracy: 0.9820 - 2s/epoch - 8ms/step\n",
            "Test accuracy: 0.9819999933242798 and Loss: 0.07282052934169769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeating 7th and 8th step of CNN model with dropout"
      ],
      "metadata": {
        "id": "PAkP3jfjOIAK"
      },
      "id": "PAkP3jfjOIAK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "MQNdMXuHDnnY"
      },
      "id": "MQNdMXuHDnnY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R600x1MYzi0m",
        "outputId": "f0a7eb48-e326-4669-b2bb-12279f943248"
      },
      "id": "R600x1MYzi0m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 25)        250       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 25)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 25)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 16900)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16900)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               1690100   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1691360 (6.45 MB)\n",
            "Trainable params: 1691360 (6.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 67s 142ms/step - loss: 0.2443 - accuracy: 0.9263 - val_loss: 0.0845 - val_accuracy: 0.9728\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 73s 155ms/step - loss: 0.0931 - accuracy: 0.9724 - val_loss: 0.0630 - val_accuracy: 0.9806\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 66s 140ms/step - loss: 0.0638 - accuracy: 0.9804 - val_loss: 0.0566 - val_accuracy: 0.9820\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 66s 141ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.0508 - val_accuracy: 0.9823\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 66s 141ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.0490 - val_accuracy: 0.9838\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 68s 145ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 0.0465 - val_accuracy: 0.9842\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 71s 151ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 0.0454 - val_accuracy: 0.9849\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 69s 146ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0462 - val_accuracy: 0.9857\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 68s 145ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0485 - val_accuracy: 0.9849\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 69s 146ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0527 - val_accuracy: 0.9850\n",
            "313/313 - 2s - loss: 0.0527 - accuracy: 0.9850 - 2s/epoch - 8ms/step\n",
            "Test accuracy: 0.9850000143051147 and Loss: 0.052743542939424515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPZDMwUeznH7"
      },
      "id": "tPZDMwUeznH7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeating 7th and 8th step of CNN model with Batch Normalization"
      ],
      "metadata": {
        "id": "h2gTd6LHObee"
      },
      "id": "h2gTd6LHObee"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "model.add(BatchNormalization())\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "1qeF5E8POben"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1qeF5E8POben"
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2e6d3a-3447-4bbb-db79-e1ea83901b98",
        "id": "A0m92oe4Oben"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 25)        250       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 26, 26, 25)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 26, 26, 25)        100       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 16900)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               1690100   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1691460 (6.45 MB)\n",
            "Trainable params: 1691410 (6.45 MB)\n",
            "Non-trainable params: 50 (200.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 60s 127ms/step - loss: 0.1555 - accuracy: 0.9542 - val_loss: 0.1627 - val_accuracy: 0.9805\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 60s 127ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0645 - val_accuracy: 0.9803\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 62s 132ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0601 - val_accuracy: 0.9819\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0767 - val_accuracy: 0.9808\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 60s 128ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0836 - val_accuracy: 0.9802\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0890 - val_accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 60s 127ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.1016 - val_accuracy: 0.9799\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1243 - val_accuracy: 0.9773\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1032 - val_accuracy: 0.9817\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 57s 122ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1057 - val_accuracy: 0.9817\n",
            "313/313 - 3s - loss: 0.1057 - accuracy: 0.9817 - 3s/epoch - 9ms/step\n",
            "Test accuracy: 0.9817000031471252 and Loss: 0.1057095006108284\n"
          ]
        }
      ],
      "id": "A0m92oe4Oben"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xbTU2GOOjhL"
      },
      "id": "6xbTU2GOOjhL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeating 7th and 8th step of CNN model with batch normalization and dropout"
      ],
      "metadata": {
        "id": "xClJ9HM6Ojwh"
      },
      "id": "xClJ9HM6Ojwh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with a linear stack of layers using the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "0GR6-Gs_Ojwi"
      },
      "execution_count": 8,
      "outputs": [],
      "id": "0GR6-Gs_Ojwi"
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_data=(x_test, y_test))\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc} and Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b750cd-5a8b-4fa0-df52-9c55da985715",
        "id": "ocBhOWhzOjwj"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 25)        250       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 26, 26, 25)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 26, 26, 25)        100       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 25)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16900)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16900)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               1690100   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 100)               400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1691860 (6.45 MB)\n",
            "Trainable params: 1691610 (6.45 MB)\n",
            "Non-trainable params: 250 (1000.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 77s 162ms/step - loss: 0.1657 - accuracy: 0.9509 - val_loss: 0.4125 - val_accuracy: 0.9347\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 75s 159ms/step - loss: 0.0613 - accuracy: 0.9819 - val_loss: 0.0623 - val_accuracy: 0.9800\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 74s 158ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.0491 - val_accuracy: 0.9834\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 73s 157ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.0535 - val_accuracy: 0.9825\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 81s 173ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0472 - val_accuracy: 0.9832\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 74s 157ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9852\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 73s 156ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0447 - val_accuracy: 0.9867\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 74s 157ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0551 - val_accuracy: 0.9849\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 74s 158ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0493 - val_accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 77s 164ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0594 - val_accuracy: 0.9841\n",
            "313/313 - 3s - loss: 0.0594 - accuracy: 0.9841 - 3s/epoch - 10ms/step\n",
            "Test accuracy: 0.9840999841690063 and Loss: 0.05937236174941063\n"
          ]
        }
      ],
      "id": "ocBhOWhzOjwj"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5shCUfhWgZZ"
      },
      "id": "J5shCUfhWgZZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}